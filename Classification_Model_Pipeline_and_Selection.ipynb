{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF9C56XM+BkJjtwm+ELGsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briangeorg/Machine_Learning_Portfolio/blob/main/Classification_Model_Pipeline_and_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What's Our Project?**\n",
        "\n",
        "We're working cross-functionally with HR to evaluate employee data; the project is to predict which employees are most likely to leave the company, enabling the organization to implement a retention program."
      ],
      "metadata": {
        "id": "dmIe4r8hIOpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Started**\n",
        "\n",
        "Below we'll ingest our raw data from Kaggle and wrangle our data into a format that's usable across our intended model types."
      ],
      "metadata": {
        "id": "VIx2w8gUH9Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"pavansubhasht/ibm-hr-analytics-attrition-dataset\",\n",
        "  file_path\n",
        ")\n",
        "# View csv data below for a basic understanding:\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "id": "PDwOS4NUIZbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Prep**\n",
        "\n",
        "First, we'll do two things:\n",
        "\n",
        "1. Remove variables we identified as non-meaningful in our Exploratory Data Analysis workbook\n",
        "\n",
        "2. Recode (one-hot encoding) our categorical variables, and implement min-max scaling across our dataset so that, regardless of which model type we implement, the data are uniformly usable (scaling your data is unnecessary in some model types, but in others, it may create serious problems!)"
      ],
      "metadata": {
        "id": "z0IS0YBEItZG"
      }
    }
  ]
}